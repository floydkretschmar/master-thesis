{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation the best parameters settings for COMPAS, Adult Credit and FICO Credit score datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.util import mean_difference\n",
    "from src.feature_map import IdentityFeatureMap\n",
    "from src.functions import cost_utility\n",
    "from src.plotting import plot_mean, plot_median\n",
    "from src.training import train\n",
    "from src.training_evaluation import UTILITY, COVARIANCE_OF_DECISION_DP\n",
    "from src.policy import LogisticPolicy\n",
    "from src.distribution import AdultCreditDistribution, COMPASDistribution\n",
    "from src.optimization import PenaltyOptimizationTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fairness Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_benefit(decisions, ips_weights):\n",
    "    if ips_weights is not None:\n",
    "        decisions *= ips_weights\n",
    "\n",
    "    return decisions\n",
    "\n",
    "\n",
    "def calc_covariance(s, decisions, ips_weights):\n",
    "    new_s = 1 - (2 * s)\n",
    "\n",
    "    if ips_weights is not None:\n",
    "        mu_s = np.mean(new_s * ips_weights, axis=0)\n",
    "        d = decisions * ips_weights\n",
    "    else:\n",
    "        mu_s = np.mean(new_s, axis=0)\n",
    "        d = decisions\n",
    "\n",
    "    covariance = (new_s - mu_s) * d\n",
    "    return covariance\n",
    "\n",
    "\n",
    "def fairness_function_gradient(type, **fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    y = fairness_kwargs[\"y\"]\n",
    "    decisions = fairness_kwargs[\"decisions\"]\n",
    "    ips_weights = fairness_kwargs[\"ips_weights\"]\n",
    "\n",
    "    if type == \"BD_DP\" or type == \"BD_EOP\":\n",
    "        result = calc_benefit(decisions, ips_weights)\n",
    "    elif type == \"COV_DP\":\n",
    "        result = calc_covariance(s, decisions, ips_weights)\n",
    "    elif type == \"COV_DP_DIST\":\n",
    "        phi = policy.feature_map(policy._extract_features(x, s))\n",
    "        distance = np.matmul(phi, policy.theta).reshape(-1, 1)\n",
    "        result = calc_covariance(s, distance, ips_weights)\n",
    "\n",
    "    log_gradient = policy.log_policy_gradient(x, s)\n",
    "    grad = log_gradient * result\n",
    "\n",
    "    if type == \"BD_DP\":\n",
    "        return mean_difference(grad, s)\n",
    "    elif type == \"COV_DP\":\n",
    "        return np.mean(grad, axis=0)\n",
    "    elif type == \"COV_DP_DIST\":\n",
    "        return np.mean(grad, axis=0)\n",
    "    elif type == \"BD_EOP\":\n",
    "        y1_indices = np.where(y == 1)\n",
    "        return mean_difference(grad[y1_indices], s[y1_indices])\n",
    "\n",
    "\n",
    "def fairness_function(type, **fairness_kwargs):\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    y = fairness_kwargs[\"y\"]\n",
    "    decisions = fairness_kwargs[\"decisions\"]\n",
    "    ips_weights = fairness_kwargs[\"ips_weights\"]\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "\n",
    "    if type == \"BD_DP\":\n",
    "        benefit = calc_benefit(decisions, ips_weights)\n",
    "        return mean_difference(benefit, s)\n",
    "    elif type == \"COV_DP\":\n",
    "        covariance = calc_covariance(s, decisions, ips_weights)\n",
    "        return np.mean(covariance, axis=0)\n",
    "    elif type == \"COV_DP_DIST\":\n",
    "        phi = policy.feature_map(policy._extract_features(x, s))\n",
    "        distance = np.matmul(phi, policy.theta).reshape(-1, 1)\n",
    "        covariance = calc_covariance(s, distance, ips_weights)\n",
    "        return np.mean(covariance, axis=0)\n",
    "    elif type == \"BD_EOP\":\n",
    "        benefit = calc_benefit(decisions, ips_weights)\n",
    "        y1_indices = np.where(y == 1)\n",
    "        return mean_difference(benefit[y1_indices], s[y1_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# COMPAS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bias = True\n",
    "distribution = COMPASDistribution(bias=bias, test_percentage=0.2)\n",
    "dim_theta = distribution.feature_dim\n",
    "\n",
    "def util_func(**util_params):\n",
    "    util = cost_utility(cost_factor=0.5, **util_params)\n",
    "    return util\n",
    "\n",
    "training_parameters = {\n",
    "    'model':{\n",
    "        'constructor': LogisticPolicy,\n",
    "        'parameters': {\n",
    "            \"theta\": np.zeros((dim_theta)),\n",
    "            \"feature_map\": IdentityFeatureMap(dim_theta),\n",
    "            \"use_sensitive_attributes\": False\n",
    "        }\n",
    "    },\n",
    "    'distribution': distribution,\n",
    "    'optimization_target': {\n",
    "        'constructor': PenaltyOptimizationTarget,\n",
    "        'parameters': {\n",
    "            'utility_function': util_func\n",
    "        }\n",
    "    },\n",
    "    'parameter_optimization': {\n",
    "        'time_steps':200,\n",
    "        'epochs': 150,\n",
    "        'batch_size':128,\n",
    "        'learning_rate': 0.01,\n",
    "        'learn_on_entire_history': False,\n",
    "        'fix_seeds': True\n",
    "    },\n",
    "    'data': {\n",
    "        'num_train_samples': 4096,\n",
    "        'num_test_samples': 1024,\n",
    "        'fix_seeds': True\n",
    "    },\n",
    "    'evaluation': {\n",
    "        UTILITY: {\n",
    "            'measure_function': lambda s, y, decisions : np.mean(util_func(s=s,\n",
    "                                                                           y=y,\n",
    "                                                                           decisions=decisions)),\n",
    "            'detailed': False\n",
    "        },\n",
    "        COVARIANCE_OF_DECISION_DP: {\n",
    "            'measure_function': lambda s, y, decisions : fairness_function(\n",
    "                type=\"COV_DP\",\n",
    "                x=None,\n",
    "                s=s,\n",
    "                y=y,\n",
    "                decisions=decisions,\n",
    "                ips_weights=None,\n",
    "                policy=None),\n",
    "            'detailed': False\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### No Fariness"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_parameters['optimization_target']['parameters']['fairness_function'] \\\n",
    "    = lambda **fp : fairness_function(\"BD_DP\", **fp)\n",
    "training_parameters['optimization_target']['parameters']['fairness_gradient_function'] \\\n",
    "    = lambda **fp : fairness_function_gradient(\"BD_DP\", **fp)\n",
    "\n",
    "training_parameters[\"save_path\"] = \"../res/local_experiments/COMPAS_BEST/NO_FAIRNESS\"\n",
    "statistics, model_parameters, run_path = train(\n",
    "    training_parameters,\n",
    "    iterations=10,\n",
    "    asynchronous=True,\n",
    "    fairness_rates=[0.0])\n",
    "\n",
    "plot_mean(x_values=range(training_parameters[\"parameter_optimization\"][\"time_steps\"] + 1),\n",
    "          x_label=\"Time steps\",\n",
    "          x_scale=\"linear\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_mean_time.png\".format(run_path))\n",
    "plot_median(x_values=range(training_parameters[\"parameter_optimization\"][\"time_steps\"] + 1),\n",
    "          x_label=\"Time steps\",\n",
    "          x_scale=\"linear\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_median_time.png\".format(run_path))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Benefit Difference: DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_parameters['optimization_target']['parameters']['fairness_function'] \\\n",
    "    = lambda **fp : fairness_function(\"BD_DP\", **fp)\n",
    "training_parameters['optimization_target']['parameters']['fairness_gradient_function'] \\\n",
    "    = lambda **fp : fairness_function_gradient(\"BD_DP\", **fp)\n",
    "# lambdas = np.logspace(-6, -4, base=10, endpoint=True, num=5).tolist()\n",
    "# lambdas.extend([0.0008, 0.0009, 0.001, 0.002, 0.003])\n",
    "# lambdas.extend(np.logspace(-3, -1, base=10, endpoint=True, num=5).tolist())\n",
    "# lambdas = np.sort(np.unique(np.array(lambdas, dtype=float)))\n",
    "lambdas = np.logspace(-6, -1, base=10, endpoint=True, num=10)\n",
    "\n",
    "# training_parameters[\"save_path_subfolder\"] = \"best-lr{}-bs{}-2\".format(\n",
    "#     training_parameters[\"parameter_optimization\"][\"learning_rate\"],\n",
    "#     training_parameters[\"parameter_optimization\"][\"batch_size\"])\n",
    "training_parameters[\"save_path\"] = \"../res/local_experiments/COMPAS_BEST/BD_DP\"\n",
    "statistics, model_parameters, run_path = train(\n",
    "    training_parameters,\n",
    "    iterations=10,\n",
    "    asynchronous=True,\n",
    "    fairness_rates=lambdas)\n",
    "\n",
    "plot_mean(x_values=lambdas,\n",
    "          x_label=\"Penalty Constant\",\n",
    "          x_scale=\"log\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_mean.png\".format(run_path))\n",
    "plot_median(x_values=lambdas,\n",
    "            x_label=\"Penalty Constant\",\n",
    "            x_scale=\"log\",\n",
    "            performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                    statistics.accuracy()],\n",
    "            fairness_measures=[statistics.demographic_parity(),\n",
    "                                 statistics.equality_of_opportunity(),\n",
    "                                 statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                                  \"Covariance of Decision (DP)\")],\n",
    "            file_path=\"{}/results_median.png\".format(run_path))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Benefit Difference: EOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_parameters['optimization_target']['parameters']['fairness_function'] \\\n",
    "    = lambda **fp : fairness_function(\"BD_EOP\", **fp)\n",
    "training_parameters['optimization_target']['parameters']['fairness_gradient_function'] \\\n",
    "    = lambda **fp : fairness_function_gradient(\"BD_EOP\", **fp)\n",
    "lambdas = [0.00001, 0.00002, 0.00003, 0.00004, 0.00005, 0.00006, 0.00007, 0.00008, 0.00009,\n",
    "           0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009,\n",
    "           0.001, 0.002]\n",
    "lambdas.extend(np.logspace(-3, -1, base=10, endpoint=True, num=5).tolist())\n",
    "lambdas = np.sort(np.unique(np.array(lambdas, dtype=float)))\n",
    "\n",
    "# training_parameters[\"save_path_subfolder\"] = \"best-lr{}-bs{}-2\".format(\n",
    "#     training_parameters[\"parameter_optimization\"][\"learning_rate\"],\n",
    "#     training_parameters[\"parameter_optimization\"][\"batch_size\"])\n",
    "training_parameters[\"save_path\"] = \"../res/local_experiments/COMPAS_BEST/BD_EOP\"\n",
    "statistics, model_parameters, run_path = train(\n",
    "    training_parameters,\n",
    "    iterations=30,\n",
    "    asynchronous=True,\n",
    "    fairness_rates=lambdas)\n",
    "\n",
    "plot_mean(x_values=lambdas,\n",
    "          x_label=\"Penalty Constant\",\n",
    "          x_scale=\"log\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_mean.png\".format(run_path))\n",
    "plot_median(x_values=lambdas,\n",
    "            x_label=\"Penalty Constant\",\n",
    "            x_scale=\"log\",\n",
    "            performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                    statistics.accuracy()],\n",
    "            fairness_measures=[statistics.demographic_parity(),\n",
    "                                 statistics.equality_of_opportunity(),\n",
    "                                 statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                                  \"Covariance of Decision (DP)\")],\n",
    "            file_path=\"{}/results_median.png\".format(run_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Covariance of decision: DP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_parameters['optimization_target']['parameters']['fairness_function'] \\\n",
    "    = lambda **fp : fairness_function(\"COV_DP\", **fp)\n",
    "training_parameters['optimization_target']['parameters']['fairness_gradient_function'] \\\n",
    "    = lambda **fp : fairness_function_gradient(\"COV_DP\", **fp)\n",
    "# lambdas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009,\n",
    "#            0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
    "#            0.01]\n",
    "lambdas = np.logspace(-6, -1, base=10, endpoint=True, num=10)\n",
    "\n",
    "training_parameters[\"save_path\"] = \"../res/local_experiments/COMPAS_BEST/COV_DP\"\n",
    "statistics, model_parameters, run_path = train(\n",
    "    training_parameters,\n",
    "    iterations=15,\n",
    "    asynchronous=True,\n",
    "    fairness_rates=lambdas)\n",
    "\n",
    "plot_mean(x_values=lambdas,\n",
    "          x_label=\"Penalty Constant\",\n",
    "          x_scale=\"log\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_mean.png\".format(run_path))\n",
    "plot_median(x_values=lambdas,\n",
    "            x_label=\"Penalty Constant\",\n",
    "            x_scale=\"log\",\n",
    "            performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                    statistics.accuracy()],\n",
    "            fairness_measures=[statistics.demographic_parity(),\n",
    "                                 statistics.equality_of_opportunity(),\n",
    "                                 statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                                  \"Covariance of Decision (DP)\")],\n",
    "            file_path=\"{}/results_median.png\".format(run_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adult Credit Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bias = True\n",
    "distribution = AdultCreditDistribution(bias=bias, test_percentage=0.2)\n",
    "dim_theta = distribution.feature_dim\n",
    "\n",
    "def util_func(**util_params):\n",
    "    util = cost_utility(cost_factor=0.5, **util_params)\n",
    "    return util\n",
    "\n",
    "training_parameters = {\n",
    "    'model':{\n",
    "        'constructor': LogisticPolicy,\n",
    "        'parameters': {\n",
    "            \"theta\": np.zeros((dim_theta)),\n",
    "            \"feature_map\": IdentityFeatureMap(dim_theta),\n",
    "            \"use_sensitive_attributes\": False\n",
    "        }\n",
    "    },\n",
    "    'distribution': distribution,\n",
    "    'optimization_target': {\n",
    "        'constructor': PenaltyOptimizationTarget,\n",
    "        'parameters': {\n",
    "            'utility_function': util_func\n",
    "        }\n",
    "    },\n",
    "    'parameter_optimization': {\n",
    "        'time_steps':200,\n",
    "        'epochs': 150,\n",
    "        'batch_size':512,\n",
    "        'learning_rate': 0.05,\n",
    "        'learn_on_entire_history': False,\n",
    "        'fix_seeds': True\n",
    "    },\n",
    "    'data': {\n",
    "        'num_train_samples': 16384,\n",
    "        'num_test_samples': 4096,\n",
    "        'fix_seeds': True\n",
    "    },\n",
    "    'evaluation': {\n",
    "        UTILITY: {\n",
    "            'measure_function': lambda s, y, decisions : np.mean(util_func(s=s,\n",
    "                                                                           y=y,\n",
    "                                                                           decisions=decisions)),\n",
    "            'detailed': False\n",
    "        },\n",
    "        COVARIANCE_OF_DECISION_DP: {\n",
    "            'measure_function': lambda s, y, decisions : fairness_function(\n",
    "                type=\"COV_DP\",\n",
    "                x=None,\n",
    "                s=s,\n",
    "                y=y,\n",
    "                decisions=decisions,\n",
    "                ips_weights=None,\n",
    "                policy=None),\n",
    "            'detailed': False\n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Benefit Difference: DP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_parameters['optimization_target']['parameters']['fairness_function'] = lambda **fp : fairness_function(\"BD_DP\", **fp)\n",
    "training_parameters['optimization_target']['parameters']['fairness_gradient_function'] = lambda **fp : fairness_function_gradient(\"BD_DP\", **fp)\n",
    "\n",
    "training_parameters[\"save_path\"] = \"../res/local_experiments/ADULT_BEST/BD_DP\"\n",
    "lambdas = np.logspace(-6, -4, base=10, endpoint=True, num=5).tolist()\n",
    "lambdas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009,\n",
    "           0.001, 0.002, 0.003]\n",
    "lambdas.extend(np.logspace(-3, -1, base=10, endpoint=True, num=5).tolist())\n",
    "lambdas = np.sort(np.unique(np.array(lambdas, dtype=float)))\n",
    "\n",
    "training_parameters[\"save_path_subfolder\"] = \"best-lr{}-bs{}\".format(\n",
    "    training_parameters[\"parameter_optimization\"][\"learning_rate\"],\n",
    "    training_parameters[\"parameter_optimization\"][\"batch_size\"])\n",
    "statistics, model_parameters, run_path = train(\n",
    "    training_parameters,\n",
    "    iterations=30,\n",
    "    asynchronous=True,\n",
    "    fairness_rates=lambdas)\n",
    "\n",
    "plot_mean(x_values=lambdas,\n",
    "          x_label=\"Penalty Constant\",\n",
    "          x_scale=\"log\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_mean.png\".format(run_path))\n",
    "plot_median(x_values=lambdas,\n",
    "            x_label=\"Penalty Constant\",\n",
    "            x_scale=\"log\",\n",
    "            performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                    statistics.accuracy()],\n",
    "            fairness_measures=[statistics.demographic_parity(),\n",
    "                                 statistics.equality_of_opportunity(),\n",
    "                                 statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                                  \"Covariance of Decision (DP)\")],\n",
    "            file_path=\"{}/results_median.png\".format(run_path))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Benefit Difference: EOP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_parameters['optimization_target']['parameters']['fairness_function'] = lambda **fp : fairness_function(\"BD_EOP\", **fp)\n",
    "training_parameters['optimization_target']['parameters']['fairness_gradient_function'] = lambda **fp : fairness_function_gradient(\"BD_EOP\", **fp)\n",
    "\n",
    "training_parameters[\"save_path\"] = \"../res/local_experiments/ADULT_BEST/BD_EOP\"\n",
    "lambdas = np.logspace(-6, -4, base=10, endpoint=True, num=5).tolist()\n",
    "lambdas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009,\n",
    "           0.001, 0.002, 0.003]\n",
    "lambdas.extend(np.logspace(-3, -1, base=10, endpoint=True, num=5).tolist())\n",
    "lambdas = np.sort(np.unique(np.array(lambdas, dtype=float)))\n",
    "\n",
    "training_parameters[\"save_path_subfolder\"] = \"best-lr{}-bs{}\".format(\n",
    "    training_parameters[\"parameter_optimization\"][\"learning_rate\"],\n",
    "    training_parameters[\"parameter_optimization\"][\"batch_size\"])\n",
    "statistics, model_parameters, run_path = train(\n",
    "    training_parameters,\n",
    "    iterations=30,\n",
    "    asynchronous=True,\n",
    "    fairness_rates=lambdas)\n",
    "\n",
    "plot_mean(x_values=lambdas,\n",
    "          x_label=\"Penalty Constant\",\n",
    "          x_scale=\"log\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_mean.png\".format(run_path))\n",
    "plot_median(x_values=lambdas,\n",
    "            x_label=\"Penalty Constant\",\n",
    "            x_scale=\"log\",\n",
    "            performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                    statistics.accuracy()],\n",
    "            fairness_measures=[statistics.demographic_parity(),\n",
    "                                 statistics.equality_of_opportunity(),\n",
    "                                 statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                                  \"Covariance of Decision (DP)\")],\n",
    "            file_path=\"{}/results_median.png\".format(run_path))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Covariance of decision: DP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_parameters['optimization_target']['parameters']['fairness_function'] = lambda **fp : fairness_function(\"COV_DP\", **fp)\n",
    "training_parameters['optimization_target']['parameters']['fairness_gradient_function'] = lambda **fp : fairness_function_gradient(\"COV_DP\", **fp)\n",
    "\n",
    "training_parameters[\"save_path\"] = \"../res/local_experiments/ADULT_BEST/COV_DP\"\n",
    "lambdas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009,\n",
    "           0.001]\n",
    "\n",
    "statistics, model_parameters, run_path = train(\n",
    "    training_parameters,\n",
    "    iterations=30,\n",
    "    asynchronous=True,\n",
    "    fairness_rates=lambdas)\n",
    "\n",
    "plot_mean(x_values=lambdas,\n",
    "          x_label=\"Penalty Constant\",\n",
    "          x_scale=\"log\",\n",
    "          performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                statistics.accuracy()],\n",
    "          fairness_measures=[statistics.demographic_parity(),\n",
    "                             statistics.equality_of_opportunity(),\n",
    "                             statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                              \"Covariance of Decision (DP)\")],\n",
    "          file_path=\"{}/results_mean.png\".format(run_path))\n",
    "plot_median(x_values=lambdas,\n",
    "            x_label=\"Penalty Constant\",\n",
    "            x_scale=\"log\",\n",
    "            performance_measures=[statistics.get_additonal_measure(UTILITY, \"Utility\"),\n",
    "                                    statistics.accuracy()],\n",
    "            fairness_measures=[statistics.demographic_parity(),\n",
    "                                 statistics.equality_of_opportunity(),\n",
    "                                 statistics.get_additonal_measure(COVARIANCE_OF_DECISION_DP,\n",
    "                                                                  \"Covariance of Decision (DP)\")],\n",
    "            file_path=\"{}/results_median.png\".format(run_path))\n",
    "\n",
    "# plt.plot(statistics.results[Statistics.X_VALUES], statistics.performance(Statistics.ACCURACY, Statistics.MEDIAN))\n",
    "# plt.savefig(\"{}/accuracy.png\".format(run_path))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}