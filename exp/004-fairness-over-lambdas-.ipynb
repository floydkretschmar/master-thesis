{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of different versions of the benefit difference fairness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from src.util import sigmoid\n",
    "from src.feature_map import IdentityFeatureMap\n",
    "from src.functions import cost_utility, demographic_parity\n",
    "from src.plotting import plot_mean_over_lambdas, plot_median_over_lambdas\n",
    "from src.training import train_multiple\n",
    "from src.distribution import SplitDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The parameters used by the the original authors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = True\n",
    "dim_x = 1\n",
    "dim_theta = dim_x + 1 if bias else dim_x\n",
    "\n",
    "lambdas = np.logspace(-1, 2, base=10, endpoint=True, num=100)\n",
    "lambdas = np.insert(arr=lambdas, obj=0, values=[0.0])\n",
    "\n",
    "iterations=30\n",
    "\n",
    "def util_func(**util_params):\n",
    "    util = cost_utility(cost_factor=0.55, **util_params)\n",
    "    return util\n",
    "\n",
    "training_parameters = {    \n",
    "    'save_path': \"/home/fkretschmar/Documents/master-thesis/res/exp-004/\",\n",
    "    'model':{\n",
    "        'theta': [-3.5, 0.6],\n",
    "        'benefit_value_function': demographic_parity,\n",
    "        'utility_value_function': util_func,\n",
    "        'feature_map': IdentityFeatureMap(dim_theta),\n",
    "        'keep_collected_data': False,\n",
    "        'use_sensitve_attributes': False,\n",
    "        'bias': bias\n",
    "    },\n",
    "    'optimization': {\n",
    "        'time_steps':200,\n",
    "        'epochs': 32,\n",
    "        'batch_size':512,\n",
    "        'learning_rate': 0.5,\n",
    "        'decay_rate': 0.8,\n",
    "        'decay_step': 30,\n",
    "        'fairness_rates': lambdas,\n",
    "        'test_at_every_timestep': False\n",
    "    },\n",
    "    'data': {\n",
    "        'distribution': SplitDistribution(bias=bias),\n",
    "        'keep_data_across_lambdas': True,\n",
    "        'fraction_protected':0.5,\n",
    "        'num_test_samples': 20480,\n",
    "        'num_decisions': 32 * 512\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct Benefit Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ntial_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\nTraceback (most recent call last):\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 164, in _policy_gradient\n    gradient = self._utility_gradient(x, s, y, decisions, ips_weights)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 173, in _policy_gradient\n    policy=self)\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 61, in __call__\n    probability = self._probability(features)\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 61, in __call__\n    probability = self._probability(features)\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"<ipython-input-3-19a4049272f1>\", line 18, in fairness_function\n    return policy._mean_difference(benefit, s) * policy._mean_difference(benefit_grad, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 127, in _mean_difference\n    target_s1 = target[s_1_idx].sum(axis=0) / len(s_1_idx)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 328, in _probability\n    return sigmoid(np.matmul(self.feature_map(features), self.theta))\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"common.pyx\", line 313, in numpy.random.common.check_array_constraint\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 173, in _policy_gradient\n    policy=self)\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 164, in _policy_gradient\n    gradient = self._utility_gradient(x, s, y, decisions, ips_weights)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 328, in _probability\n    return sigmoid(np.matmul(self.feature_map(features), self.theta))\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 61, in __call__\n    probability = self._probability(features)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 173, in _policy_gradient\n    policy=self)\nKeyboardInterrupt\n  File \"/home/fkretschmar/Documents/master-thesis/src/training.py\", line 128, in _train_single\n    for u, bd, pi in consequential_learning(**training_parameters):\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 318, in _utility_gradient\n    log_gradient = self._log_gradient(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 319, in _utility_gradient\n    utility = self.utility_function(decisions=decisions, y=y)\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/util.py\", line 11, in sigmoid\n    np.exp(x) / (1 + np.exp(x)))\n  File \"<ipython-input-3-19a4049272f1>\", line 14, in fairness_function\n    log_gradient = policy._log_gradient(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 173, in _policy_gradient\n    policy=self)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 328, in _probability\n    return sigmoid(np.matmul(self.feature_map(features), self.theta))\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 315, in _log_gradient\n    return phi/np.expand_dims(1.0 + np.exp(np.matmul(phi, self.theta)), axis=1)\nKeyboardInterrupt\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 315, in _log_gradient\n    return phi/np.expand_dims(1.0 + np.exp(np.matmul(phi, self.theta)), axis=1)\n  File \"<ipython-input-2-08d1d7e060f7>\", line 11, in util_func\n    util = cost_utility(cost_factor=0.55, **util_params)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 63, in __call__\n    return np.expand_dims(np.random.binomial(1, probability).astype(float), axis=1)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 173, in _policy_gradient\n    policy=self)\n  File \"<ipython-input-3-19a4049272f1>\", line 18, in fairness_function\n    return policy._mean_difference(benefit, s) * policy._mean_difference(benefit_grad, s)\nKeyboardInterrupt\n  File \"mtrand.pyx\", line 3074, in numpy.random.mtrand.RandomState.binomial\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 164, in _policy_gradient\n    gradient = self._utility_gradient(x, s, y, decisions, ips_weights)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/functions.py\", line 17, in cost_utility\n    return decisions * (y - cost_factor)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 61, in __call__\n    probability = self._probability(features)\n  File \"<__array_function__ internals>\", line 2, in any\n  File \"<ipython-input-3-19a4049272f1>\", line 18, in fairness_function\n    return policy._mean_difference(benefit, s) * policy._mean_difference(benefit_grad, s)\n  File \"<ipython-input-3-19a4049272f1>\", line 18, in fairness_function\n    return policy._mean_difference(benefit, s) * policy._mean_difference(benefit_grad, s)\nKeyboardInterrupt\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 328, in _probability\n    return sigmoid(np.matmul(self.feature_map(features), self.theta))\n  File \"/home/fkretschmar/Documents/master-thesis/src/util.py\", line 10, in sigmoid\n    1 / (1 + np.exp(-x)),\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 63, in __call__\n    return np.expand_dims(np.random.binomial(1, probability).astype(float), axis=1)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 121, in _mean_difference\n    s_1_idx = s_idx[s == 1]\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/home/fkretschmar/Documents/master-thesis/src/consequential_learning.py\", line 95, in consequential_learning\n    pi.update(x, s, y, learning_rate, training_args[\"optimization\"][\"batch_size\"], training_args[\"optimization\"][\"epochs\"])\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 126, in _mean_difference\n    target_s0 = target[s_0_idx].sum(axis=0) / len(s_0_idx)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 322, in _utility_gradient\n    utility = ips_weights * utility\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"mtrand.pyx\", line 3074, in numpy.random.mtrand.RandomState.binomial\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 121, in _mean_difference\n    s_1_idx = s_idx[s == 1]\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/site-packages/numpy/core/_methods.py\", line 38, in _sum\n    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\nKeyboardInterrupt\n  File \"common.pyx\", line 313, in numpy.random.common.check_array_constraint\n  File \"/home/fkretschmar/Documents/master-thesis/src/util.py\", line 11, in sigmoid\n    np.exp(x) / (1 + np.exp(x)))\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 257, in update\n    gradient = self._policy_gradient(X_batch, S_batch, Y_batch, ips_weights_batch)\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"<__array_function__ internals>\", line 6, in any\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 63, in __call__\n    return np.expand_dims(np.random.binomial(1, probability).astype(float), axis=1)\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 2270, in any\n    return _wrapreduction(a, np.logical_or, 'any', axis, None, out, keepdims=keepdims)\n  File \"<__array_function__ internals>\", line 6, in expand_dims\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 85, in _wrapreduction\n    if dtype is not None:\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/site-packages/numpy/lib/shape_base.py\", line 574, in expand_dims\n    a = asanyarray(a)\nKeyboardInterrupt\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 161, in _policy_gradient\n    decisions = self(x, s)\n  File \"/home/fkretschmar/Documents/master-thesis/src/policy.py\", line 63, in __call__\n    return np.expand_dims(np.random.binomial(1, probability).astype(float), axis=1)\nKeyboardInterrupt\n  File \"/home/fkretschmar/miniconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\nKeyboardInterrupt\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-19a4049272f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtraining_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fairness_function'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfairness_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplot_mean_over_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"results_mean.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/master-thesis/src/training.py\u001b[0m in \u001b[0;36mtrain_multiple\u001b[0;34m(training_parameters, iterations, verbose, asynchronous)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_train_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_result_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In unknown state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fairness_function(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    y = fairness_kwargs[\"y\"]\n",
    "    decisions = fairness_kwargs[\"decisions\"]\n",
    "    ips_weights = fairness_kwargs[\"ips_weights\"]\n",
    "\n",
    "    benefit = policy.benefit_function(decisions=decisions, y=y)\n",
    "\n",
    "    if ips_weights is not None:\n",
    "        benefit *= ips_weights\n",
    "\n",
    "    log_gradient = policy._log_gradient(x, s)\n",
    "    benefit_grad = benefit * log_gradient\n",
    "        \n",
    "    # benefit-difference * grad-benefit-difference\n",
    "    return policy._mean_difference(benefit, s) * policy._mean_difference(benefit_grad, s)\n",
    "\n",
    "training_parameters[\"model\"]['fairness_function'] = fairness_function\n",
    "\n",
    "statistics = train_multiple(training_parameters, iterations=iterations, verbose=True, asynchronous=True)\n",
    "\n",
    "plot_mean_over_lambdas(statistics, \"results_mean.png\")\n",
    "plot_median_over_lambdas(statistics, \"results_median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('miniconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitminiconda3virtualenv5e66bc8af94a4b3dad75094b6163158a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}