{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of a comparison of COMPAS data across all fairness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from src.util import sigmoid, load_dataset\n",
    "from src.feature_map import IdentityFeatureMap\n",
    "from src.functions import cost_utility, demographic_parity\n",
    "from src.plotting import plot_mean, plot_median\n",
    "from src.training import train\n",
    "from src.distribution import ResamplingDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncalibrated Score: Benefit Difference: Benefit Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_benefit(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    y = fairness_kwargs[\"y\"]\n",
    "    decisions = fairness_kwargs[\"decisions\"]\n",
    "    ips_weights = fairness_kwargs[\"ips_weights\"]\n",
    "\n",
    "    benefit = policy.benefit_function(decisions=decisions, y=y)\n",
    "\n",
    "    if ips_weights is not None:\n",
    "        benefit *= ips_weights\n",
    "\n",
    "    return benefit\n",
    "\n",
    "def fairness_gradient_function(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    benefit = calc_benefit(**fairness_kwargs)\n",
    "\n",
    "    log_gradient = policy._log_policy_gradient(x, s)\n",
    "    benefit_grad = log_gradient * benefit\n",
    "        \n",
    "    return policy._mean_difference(benefit_grad, s)\n",
    "\n",
    "def fairness_function(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    benefit = calc_benefit(**fairness_kwargs)\n",
    "        \n",
    "    return policy._mean_difference(benefit, s)\n",
    "\n",
    "bias = True\n",
    "dim_x = 1\n",
    "dim_theta = dim_x + 1 if bias else dim_x\n",
    "\n",
    "def util_func(**util_params):\n",
    "    util = cost_utility(cost_factor=0.6, **util_params)\n",
    "    return util\n",
    "\n",
    "training_parameters = {    \n",
    "    'save_path': './',\n",
    "    'model':{\n",
    "        'benefit_function': demographic_parity,\n",
    "        'utility_function': util_func,\n",
    "        'fairness_function': fairness_function,\n",
    "        'fairness_gradient_function': fairness_gradient_function,\n",
    "        'feature_map': IdentityFeatureMap(dim_theta),\n",
    "        'learn_on_entire_history': False,\n",
    "        'use_sensitve_attributes': False,\n",
    "        'bias': bias,\n",
    "        'initial_theta': [-0.1, 0.7]\n",
    "    },\n",
    "    'parameter_optimization': {\n",
    "        'time_steps':200,\n",
    "        'epochs': 3,\n",
    "        'batch_size':64,\n",
    "        'learning_rate': 0.1,\n",
    "        'decay_rate': 1,\n",
    "        'decay_step': 10000,\n",
    "        'num_decisions': 40 * 64\n",
    "    },\n",
    "    'data': {\n",
    "        'distribution': ResamplingDistribution(bias=bias, dataset=load_dataset(\"../dat/compas/compas.npz\"), test_percentage=0.2),\n",
    "        'num_test_samples': 64**2\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-uncalibrated-over-time\"\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = 0.0\n",
    "\n",
    "statistics, _, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_time.png\".format(run_path))\n",
    "plot_median(statistics, \"{}/results_median_time.png\".format(run_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-uncalibrated-over-lambdas\"\n",
    "lambdas = np.logspace(-2, 1, base=10, endpoint=True, num=20)\n",
    "lambdas = np.insert(arr=lambdas, obj=0, values=[0.0])\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = lambdas\n",
    "\n",
    "statistics, model_parameters, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_lambdas.png\".format(run_path))\n",
    "plot_median(statistics, \"{}/results_median_lambdas.png\".format(run_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-uncalibrated\"\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = 0.0\n",
    "training_parameters[\"lagrangian_optimization\"] = {\n",
    "    'iterations': 30,\n",
    "    'epochs': 1,\n",
    "    'batch_size':256,\n",
    "    'learning_rate': 1,\n",
    "    'decay_rate': 1,\n",
    "    'decay_step': 10000,\n",
    "    'num_decisions': 128 * 256\n",
    "}\n",
    "\n",
    "statistics, model_parameters, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_lambdas.png\".format(run_path), model_parameters=model_parameters)\n",
    "plot_median(statistics, \"{}/results_median_lambdas.png\".format(run_path), model_parameters=model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncalibrated Score: Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_covariance(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    y = fairness_kwargs[\"y\"]\n",
    "    decisions = fairness_kwargs[\"decisions\"]\n",
    "    ips_weights = fairness_kwargs[\"ips_weights\"]\n",
    "\n",
    "    benefit = policy.benefit_function(decisions=decisions, y=y)\n",
    "\n",
    "    if ips_weights is not None:\n",
    "        mu_s = np.mean(s * ips_weights, axis=0)\n",
    "        benefit *= ips_weightsining_parameters\n",
    "    else:\n",
    "        mu_s = np.mean(s, axis=0)\n",
    "\n",
    "    covariance = (s - mu_s) * benefit\n",
    "    return covariance\n",
    "\n",
    "def fairness_gradient_function(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    covariance = calc_covariance(**fairness_kwargs)\n",
    "\n",
    "    log_policy_gradient = policy._log_policy_gradient(x, s)\n",
    "    covariance_grad = log_policy_gradient * covariance\n",
    "\n",
    "    return np.mean(covariance_grad, axis=0)\n",
    "\n",
    "def fairness_function(**fairness_kwargs):\n",
    "    covariance = calc_covariance(**fairness_kwargs)\n",
    "    return np.mean(covariance, axis=0)\n",
    "\n",
    "bias = True\n",
    "dim_x = 1\n",
    "dim_theta = dim_x + 1 if bias else dim_x\n",
    "\n",
    "def util_func(**util_params):\n",
    "    util = cost_utility(cost_factor=0.142, **util_params)\n",
    "    return util\n",
    "\n",
    "training_parameters = {    \n",
    "    'save': True,\n",
    "    'save_path': './',\n",
    "    'model':{\n",
    "        'benefit_function': demographic_parity,\n",
    "        'utility_function': util_func,\n",
    "        'fairness_function': fairness_function,\n",
    "        'fairness_gradient_function': fairness_gradient_function,\n",
    "        'feature_map': IdentityFeatureMap(dim_theta),\n",
    "        'learn_on_entire_history': False,\n",
    "        'use_sensitve_attributes': False,\n",
    "        'bias': bias,\n",
    "        'initial_theta': [-3.0, 5.0]\n",
    "    },\n",
    "    'parameter_optimization': {\n",
    "        'time_steps':200,\n",
    "        'epochs': 1,\n",
    "        'batch_size':256,\n",
    "        'learning_rate': 1,\n",
    "        'decay_rate': 1,\n",
    "        'decay_step': 10000,\n",
    "        'num_decisions': 128 * 256\n",
    "    },\n",
    "    'data': {\n",
    "        'distribution': UncalibratedScore(bias=bias, fraction_protected=0.5),\n",
    "        'num_test_samples': 8192\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-cov-uncalibrated-over-time\"\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = 0.0\n",
    "\n",
    "statistics, _, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_time.png\".format(run_path))\n",
    "plot_median(statistics, \"{}/results_median_time.png\".format(run_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-cov-uncalibrated-over-lambdas\"\n",
    "lambdas = np.logspace(-3, 0, base=10, endpoint=True, num=19)\n",
    "lambdas = np.insert(arr=lambdas, obj=0, values=[0.0])\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = lambdas\n",
    "\n",
    "statistics, _, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_lambdas.png\".format(run_path))\n",
    "plot_median(statistics, \"{}/results_median_lambdas.png\".format(run_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-cov-uncalibrated\"\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = 0.0\n",
    "training_parameters[\"lagrangian_optimization\"] = {\n",
    "    'iterations': 20,\n",
    "    'epochs': 1,\n",
    "    'batch_size':256,\n",
    "    'learning_rate': 0.00001,\n",
    "    'decay_rate': 1,\n",
    "    'decay_step': 10000,\n",
    "    'num_decisions': 128 * 256\n",
    "}\n",
    "\n",
    "statistics, model_parameters, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_lambdas.png\".format(run_path), model_parameters=model_parameters)\n",
    "plot_median(statistics, \"{}/results_median_lambdas.png\".format(run_path), model_parameters=model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def indcator_benefit(**fairness_kwargs):\n",
    "#     policy = fairness_kwargs[\"policy\"]\n",
    "#     x = fairness_kwargs[\"x\"]\n",
    "#     s = fairness_kwargs[\"s\"]\n",
    "#     y = fairness_kwargs[\"y\"]\n",
    "#     decisions = fairness_kwargs[\"decisions\"]\n",
    "#     ips_weights = fairness_kwargs[\"ips_weights\"]\n",
    "\n",
    "#     benefit = policy.benefit_function(decisions=decisions, y=y)\n",
    "\n",
    "#     if ips_weights is not None:\n",
    "#         benefit *= ips_weights\n",
    "\n",
    "#     indicator_s0 = np.where(s == 0, s, 1)\n",
    "#     indicator_s1 = np.where(s == 1, s, -1)\n",
    "#     indicator = indicator_s0 + indicator_s1\n",
    "\n",
    "#     return indicator * benefit\n",
    "\n",
    "def indcator_benefit(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    y = fairness_kwargs[\"y\"]\n",
    "    decisions = fairness_kwargs[\"decisions\"]\n",
    "    ips_weights = fairness_kwargs[\"ips_weights\"]\n",
    "\n",
    "    benefit = policy.benefit_function(decisions=decisions, y=y)\n",
    "\n",
    "    if ips_weights is not None:\n",
    "        benefit *= ips_weights\n",
    "\n",
    "    return (1 - (2 * s)) * benefit\n",
    "\n",
    "def fairness_gradient_function(**fairness_kwargs):\n",
    "    policy = fairness_kwargs[\"policy\"]\n",
    "    x = fairness_kwargs[\"x\"]\n",
    "    s = fairness_kwargs[\"s\"]\n",
    "    covariance = indcator_benefit(**fairness_kwargs)\n",
    "\n",
    "    log_policy_gradient = policy._log_policy_gradient(x, s)\n",
    "    covariance_grad = log_policy_gradient * covariance\n",
    "\n",
    "    return np.mean(covariance_grad, axis=0)\n",
    "\n",
    "def fairness_function(**fairness_kwargs):\n",
    "    covariance = indcator_benefit(**fairness_kwargs)\n",
    "    return np.mean(covariance, axis=0)\n",
    "\n",
    "bias = True\n",
    "dim_x = 1\n",
    "dim_theta = dim_x + 1 if bias else dim_x\n",
    "\n",
    "def util_func(**util_params):\n",
    "    util = cost_utility(cost_factor=0.142, **util_params)\n",
    "    return util\n",
    "\n",
    "training_parameters = {    \n",
    "    'save': True,\n",
    "    'save_path': './',\n",
    "    'model':{\n",
    "        'benefit_function': demographic_parity,\n",
    "        'utility_function': util_func,\n",
    "        'fairness_function': fairness_function,\n",
    "        'fairness_gradient_function': fairness_gradient_function,\n",
    "        'feature_map': IdentityFeatureMap(dim_theta),\n",
    "        'learn_on_entire_history': False,\n",
    "        'use_sensitve_attributes': False,\n",
    "        'bias': bias,\n",
    "        'initial_theta': [-3.0, 5.0]\n",
    "    },\n",
    "    'parameter_optimization': {\n",
    "        'time_steps':200,\n",
    "        'epochs': 1,\n",
    "        'batch_size':256,\n",
    "        'learning_rate': 1,\n",
    "        'decay_rate': 1,\n",
    "        'decay_step': 10000,\n",
    "        'num_decisions': 128 * 256\n",
    "    },\n",
    "    'data': {\n",
    "        'distribution': UncalibratedScore(bias=bias, fraction_protected=0.5),\n",
    "        'num_test_samples': 8192\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-3rd-uncalibrated-over-lambdas\"\n",
    "lambdas = np.logspace(-2, 1, base=10, endpoint=True, num=19)\n",
    "lambdas = np.insert(arr=lambdas, obj=0, values=[0.0])\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = lambdas\n",
    "\n",
    "statistics, _, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_lambdas.png\".format(run_path))\n",
    "plot_median(statistics, \"{}/results_median_lambdas.png\".format(run_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters[\"experiment_name\"] = \"exp-011-3rd-uncalibrated\"\n",
    "training_parameters[\"model\"][\"initial_lambda\"] = 0.0\n",
    "training_parameters[\"lagrangian_optimization\"] = {\n",
    "    'iterations': 20,\n",
    "    'epochs': 1,\n",
    "    'batch_size':256,\n",
    "    'learning_rate': 0.5,\n",
    "    'decay_rate': 1,\n",
    "    'decay_step': 10000,\n",
    "    'num_decisions': 128 * 256\n",
    "}\n",
    "\n",
    "statistics, model_parameters, run_path = train(training_parameters, iterations=30, asynchronous=True)\n",
    "\n",
    "plot_mean(statistics, \"{}/results_mean_lambdas.png\".format(run_path), model_parameters=model_parameters)\n",
    "plot_median(statistics, \"{}/results_median_lambdas.png\".format(run_path), model_parameters=model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('miniconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitminiconda3virtualenv5e66bc8af94a4b3dad75094b6163158a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}